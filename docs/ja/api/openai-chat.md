# OpenAI 対話フォーマット（Chat Completions）

!!! info "公式ドキュメント"
    [OpenAI Chat](https://platform.openai.com/docs/api-reference/chat)

## 📝 概要

一連の対話メッセージのリストが与えられると、モデルは応答を返します。関連するガイドについては、OpenAI公式サイトを参照してください：[Chat Completions](https://platform.openai.com/docs/guides/chat)

## 💡 リクエスト例

### 基本的なテキスト対話 ✅

```bash
curl https://你的newapi服务器地址/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "developer",
        "content": "你是一个有帮助的助手。"
      },
      {
        "role": "user",
        "content": "你好！"
      }
    ]
  }'
```

**レスポンス例:**

```json
{
  "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
  "object": "chat.completion",
  "created": 1741569952,
  "model": "gpt-4.1-2025-04-14",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "你好！我能为你提供什么帮助？",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default"
}
```

### 画像分析対話 ✅

```bash
curl https://你的newapi服务器地址/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "这张图片里有什么？"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
            }
          }
        ]
      }
    ],
    "max_tokens": 300
  }'
```

**レスポンス例:**

```json
{
  "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
  "object": "chat.completion",
  "created": 1741570283,
  "model": "gpt-4.1-2025-04-14",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "图片展示了一条穿过茂密绿色草地或草甸的木制栈道。天空湛蓝，点缀着几朵散落的云彩，给整个场景营造出宁静祥和的氛围。背景中可以看到树木和灌木丛。",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1117,
    "completion_tokens": 46,
    "total_tokens": 1163,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default",
  "system_fingerprint": "fp_fc9f1d7035"
}
```

### ストリーミングレスポンス ✅

```bash
curl https://你的newapi服务器地址/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "developer",
        "content": "你是一个有帮助的助手。"
      },
      {
        "role": "user",
        "content": "你好！"
      }
    ],
    "stream": true
  }'
```

**ストリーミングレスポンス例:**

```jsonl
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"你好"},"logprobs":null,"finish_reason":null}]}

// ... 更多数据块 ...

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

### 関数呼び出し ✅

```bash
curl https://你的newapi服务器地址/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "user",
        "content": "波士顿今天的天气怎么样？"
      }
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_current_weather",
          "description": "获取指定位置的当前天气",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "城市和州，例如 San Francisco, CA"
              },
              "unit": {
                "type": "string",
                "enum": ["celsius", "fahrenheit"]
              }
            },
            "required": ["location"]
          }
        }
      }
    ],
    "tool_choice": "auto"
  }'
```

**レスポンス例:**

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1699896916,
  "model": "gpt-4o-mini",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_current_weather",
              "arguments": "{\n\"location\": \"Boston, MA\"\n}"
            }
          }
        ]
      },
      "logprobs": null,
      "finish_reason": "tool_calls"
    }
  ],
  "usage": {
    "prompt_tokens": 82,
    "completion_tokens": 17,
    "total_tokens": 99,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

### Logprobs リクエスト ✅

```bash
curl https://你的newapi服务器地址/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "user",
        "content": "你好！"
      }
    ],
    "logprobs": true,
    "top_logprobs": 2
  }'
```

**レスポンス例:**

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1702685778,
  "model": "gpt-4o-mini",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "你好！我能为你提供什么帮助？"
      },
      "logprobs": {
        "content": [
          {
            "token": "Hello",
            "logprob": -0.31725305,
            "bytes": [72, 101, 108, 108, 111],
            "top_logprobs": [
              {
                "token": "Hello",
                "logprob": -0.31725305,
                "bytes": [72, 101, 108, 108, 111]
              },
              {
                "token": "Hi",
                "logprob": -1.3190403,
                "bytes": [72, 105]
              }
            ]
          },
          {
            "token": "!",
            "logprob": -0.02380986,
            "bytes": [
              33
            ],
            "top_logprobs": [
              {
                "token": "!",
                "logprob": -0.02380986,
                "bytes": [33]
              },
              {
                "token": " there",
                "logprob": -3.787621,
                "bytes": [32, 116, 104, 101, 114, 101]
              }
            ]
          },
          {
            "token": " How",
            "logprob": -0.000054669687,
            "bytes": [32, 72, 111, 119],
            "top_logprobs": [
              {
                "token": " How",
                "logprob": -0.000054669687,
                "bytes": [32, 72, 111, 119]
              },
              {
                "token": "<|end|>",
                "logprob": -10.953937,
                "bytes": null
              }
            ]
          },
          {
            "token": " can",
            "logprob": -0.015801601,
            "bytes": [32, 99, 97, 110],
            "top_logprobs": [
              {
                "token": " can",
                "logprob": -0.015801601,
                "bytes": [32, 99, 97, 110]
              },
              {
                "token": " may",
                "logprob": -4.161023,
                "bytes": [32, 109, 97, 121]
              }
            ]
          },
          {
            "token": " I",
            "logprob": -3.7697225e-6,
            "bytes": [
              32,
              73
            ],
            "top_logprobs": [
              {
                "token": " I",
                "logprob": -3.7697225e-6,
                "bytes": [32, 73]
              },
              {
                "token": " assist",
                "logprob": -13.596657,
                "bytes": [32, 97, 115, 115, 105, 115, 116]
              }
            ]
          },
          {
            "token": " assist",
            "logprob": -0.04571125,
            "bytes": [32, 97, 115, 115, 105, 115, 116],
            "top_logprobs": [
              {
                "token": " assist",
                "logprob": -0.04571125,
                "bytes": [32, 97, 115, 115, 105, 115, 116]
              },
              {
                "token": " help",
                "logprob": -3.1089056,
                "bytes": [32, 104, 101, 108, 112]
              }
            ]
          },
          {
            "token": " you",
            "logprob": -5.4385737e-6,
            "bytes": [32, 121, 111, 117],
            "top_logprobs": [
              {
                "token": " you",
                "logprob": -5.4385737e-6,
                "bytes": [32, 121, 111, 117]
              },
              {
                "token": " today",
                "logprob": -12.807695,
                "bytes": [32, 116, 111, 100, 97, 121]
              }
            ]
          },
          {
            "token": " today",
            "logprob": -0.0040071653,
            "bytes": [32, 116, 111, 100, 97, 121],
            "top_logprobs": [
              {
                "token": " today",
                "logprob": -0.0040071653,
                "bytes": [32, 116, 111, 100, 97, 121]
              },
              {
                "token": "?",
                "logprob": -5.5247097,
                "bytes": [63]
              }
            ]
          },
          {
            "token": "?",
            "logprob": -0.0008108172,
            "bytes": [63],
            "top_logprobs": [
              {
                "token": "?",
                "logprob": -0.0008108172,
                "bytes": [63]
              },
              {
                "token": "?\n",
                "logprob": -7.184561,
                "bytes": [63, 10]
              }
            ]
          }
        ]
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 9,
    "total_tokens": 18,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": null
}
```

## 📮 リクエスト

### エンドポイント

```
POST /v1/chat/completions
```

与えられたチャット対話に対するモデル応答を作成します。詳細については、テキスト生成、ビジョン、およびオーディオのガイドを参照してください。

### 認証方法

リクエストヘッダーに以下を含めてAPIキー認証を行います：

```
Authorization: Bearer $NEWAPI_API_KEY
```

ここで `$NEWAPI_API_KEY` はあなたの API キーです。APIキーは、OpenAIプラットフォームのAPIキーページで見つけるか、生成できます。

### リクエストボディパラメータ

#### `messages`

- タイプ：配列
- 必須：はい

これまでの対話を含むメッセージのリスト。使用するモデルに応じて、テキスト、画像、音声など、さまざまなメッセージタイプ（形式）がサポートされています。

| メッセージタイプ | 説明 |
|---------|------|
| **Developer message** | 開発者が提供する指示。モデルはユーザーが送信するメッセージに関係なく、これらの指示に従う必要があります。o1モデル以降では、開発者メッセージが以前のシステムメッセージに取って代わります。 |
| **System message** | 開発者が提供する指示。モデルはユーザーが送信するメッセージに関係なく、これらの指示に従う必要があります。o1モデル以降では、代わりに開発者メッセージを使用してください。 |
| **User message** | エンドユーザーから送信されるメッセージ。プロンプトまたは追加のコンテキスト情報を含みます。 |
| **Assistant message** | ユーザーメッセージに応答してモデルが送信するメッセージ。 |
| **Tool message** | ツールメッセージの内容。 |
| **Function message** | 非推奨。 |

**Developer message 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `role` | 文字列 | はい | メッセージ作成者のロール。ここでは `developer`。 |
| `content` | 文字列または配列 | はい | 開発者メッセージの内容。テキストコンテンツ（文字列）またはコンテンツパーツの配列にすることができます。 |
| `name` | 文字列 | いいえ | 参加者のオプションの名前。モデルが同じロールの参加者を区別するために情報を提供します。 |

**System message 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `role` | 文字列 | はい | メッセージ作成者のロール。ここでは `system`。 |
| `content` | 文字列または配列 | はい | システムメッセージの内容。テキストコンテンツ（文字列）またはコンテンツパーツの配列にすることができます。 |
| `name` | 文字列 | いいえ | 参加者のオプションの名前。モデルが同じロールの参加者を区別するために情報を提供します。 |

**User message 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `role` | 文字列 | はい | メッセージ作成者のロール。ここでは `user`。 |
| `content` | 文字列または配列 | はい | ユーザーメッセージの内容。テキストコンテンツ（文字列）またはコンテンツパーツの配列にすることができます。 |
| `name` | 文字列 | いいえ | 参加者のオプションの名前。モデルが同じロールの参加者を区別するために情報を提供します。 |

**コンテンツパーツタイプ：**

| コンテンツパーツタイプ | 説明 | 使用可能 |
|------------|------|---------|
| **テキストコンテンツ部分** | テキスト入力。 | すべてのメッセージタイプ |
| **画像コンテンツ部分** | 画像入力。 | ユーザーメッセージ |
| **音声コンテンツ部分** | 音声入力。 | ユーザーメッセージ |
| **ファイルコンテンツ部分** | ファイル入力。テキスト生成に使用されます。 | ユーザーメッセージ |
| **拒否コンテンツ部分** | モデルによって生成された拒否メッセージ。 | アシスタントメッセージ |

**テキストコンテンツ部分属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `text` | 文字列 | はい | テキストコンテンツ。 |
| `type` | 文字列 | はい | コンテンツパーツのタイプ。 |

**画像コンテンツ部分属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `image_url` | オブジェクト | はい | 画像URLまたはbase64エンコードされた画像データを含むオブジェクト。 |
| `type` | 文字列 | はい | コンテンツパーツのタイプ。 |

**画像URLオブジェクト属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `url` | 文字列 | はい | 画像のURLまたはbase64エンコードされた画像データ。 |
| `detail` | 文字列 | いいえ | 画像の詳細レベルを指定します。デフォルトは `auto` です。 |

**音声コンテンツ部分属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `input_audio` | オブジェクト | はい | 音声データを含むオブジェクト。 |
| `type` | 文字列 | はい | コンテンツパーツのタイプ。常に `input_audio` です。 |

**音声入力オブジェクト属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `data` | 文字列 | はい | base64エンコードされた音声データ。 |
| `format` | 文字列 | はい | エンコードされた音声データのフォーマット。現在 "wav" および "mp3" がサポートされています。 |

**ファイルコンテンツ部分属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `file` | オブジェクト | はい | ファイルデータを含むオブジェクト。 |
| `type` | 文字列 | はい | コンテンツパーツのタイプ。常に `file` です。 |

**ファイルオブジェクト属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `file_data` | 文字列 | いいえ | base64エンコードされたファイルデータ。ファイルを文字列としてモデルに渡すために使用されます。 |
| `file_id` | 文字列 | いいえ | アップロードされたファイルのID。入力として使用されます。 |
| `filename` | 文字列 | いいえ | ファイル名。ファイルを文字列としてモデルに渡すために使用されます。 |

**Assistant message 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `role` | 文字列 | はい | メッセージ作成者のロール。ここでは `assistant`。 |
| `content` | 文字列または配列 | いいえ | アシスタントメッセージの内容。\`tool_calls\` または \`function_call\` が指定されていない限り必須です。 |
| `name` | 文字列 | いいえ | 参加者のオプションの名前。モデルが同じロールの参加者を区別するために情報を提供します。 |
| `audio` | オブジェクトまたはnull | いいえ | モデルの以前の音声応答に関するデータ。 |
| `function_call` | オブジェクトまたはnull | いいえ | 非推奨。\`tool_calls\` に置き換えられました。モデルによって生成された、呼び出すべき関数の名前と引数。 |
| `tool_calls` | 配列 | いいえ | モデルによって生成された、関数呼び出しなどのツール呼び出し。 |
| `refusal` | 文字列またはnull | いいえ | アシスタントの拒否メッセージ。 |

**Tool message 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `role` | 文字列 | はい | メッセージ作成者のロール。ここでは `tool`。 |
| `content` | 文字列または配列 | はい | ツールメッセージの内容。 |
| `tool_call_id` | 文字列 | はい | このメッセージが応答するツール呼び出し。 |

**Function message 属性：（非推奨）**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `role` | 文字列 | はい | メッセージ作成者のロール。ここでは `function`。 |
| `content` | 文字列またはnull | はい | 関数メッセージの内容。 |
| `name` | 文字列 | はい | 呼び出す関数の名前。 |

#### `model`

- タイプ：文字列
- 必須：はい

使用するモデル ID。Chat APIでどのモデルが利用可能かについては、モデルエンドポイント互換性表を参照してください。

#### `store` 

- タイプ：ブール値または null
- 必須：いいえ
- デフォルト値：false

このチャット補完リクエストの出力を、当社のモデル蒸留または評価製品のために保存するかどうか。

#### `reasoning_effort`

- タイプ：文字列または null
- 必須：いいえ
- デフォルト値：medium
- oシリーズのモデルにのみ適用

推論モデルの推論作業を制約します。現在サポートされている値は `low`、`medium`、および `high` です。推論作業を減らすと、応答が速くなり、応答で推論に使用されるトークン数が減少する可能性があります。

#### `metadata`

- タイプ：map
- 必須：いいえ

オブジェクトに添付できる16個のキーと値のペアのコレクション。これは、オブジェクトに関する追加情報を構造化された形式で保存するのに役立ち、APIまたはダッシュボードを通じてオブジェクトをクエリできます。

キーは最大長64文字の文字列です。値は最大長512文字の文字列です。

#### `modalities`

- タイプ：配列または null
- 必須：いいえ

このリクエストに対してモデルに生成させたい出力タイプ。ほとんどのモデルはテキストを生成でき、これがデフォルトです：
["text"]

モデルは音声を生成するためにも使用できます。このモデルにテキストと音声の両方の応答を生成するようにリクエストするには、以下を使用できます：
["text", "audio"]

#### `prediction`

- タイプ：オブジェクト
- 必須：いいえ

予測出力の構成。モデル応答の大部分が事前にわかっている場合に、応答時間を大幅に改善できます。これは、ファイルにわずかな変更を加える場合に最も一般的です。

**可能なタイプ：**

| タイプ | 説明 |
|------|------|
| **静的コンテンツ** | 静的な予測出力コンテンツ。例えば、わずかな変更を加えて再生成しているテキストファイルの内容など。 |

**静的コンテンツ属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `content` | 文字列または配列 | はい | 生成モデル応答と一致する必要があるコンテンツ。生成されたトークンがこのコンテンツと一致する場合、モデル応答全体がより速く返される可能性があります。 |
| `type` | 文字列 | はい | 提供する予測コンテンツのタイプ。現在のタイプは常に `content` です。 |

**コンテンツの可能なタイプ：**

1. **テキストコンテンツ（文字列）** - 予測出力に使用するコンテンツ。これは通常、わずかな変更を加えている、再生成中のファイルのテキストです。

2. **コンテンツパーツ配列（配列）** - 定義されたタイプを持つコンテンツパーツの配列。サポートされるオプションは、応答の生成に使用されるモデルによって異なります。テキスト入力を含めることができます。

**コンテンツパーツ配列属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `text` | 文字列 | はい | テキストコンテンツ。 |
| `type` | 文字列 | はい | コンテンツパーツのタイプ。 |

#### `audio`

- タイプ：オブジェクトまたは null
- 必須：いいえ

音声出力のパラメータ。`modalities: ["audio"]` を使用して音声出力がリクエストされた場合に必要です。

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `format` | 文字列 | はい | 出力音声フォーマットを指定します。wav、mp3、flac、opus、または pcm16 のいずれかである必要があります。 |
| `voice` | 文字列 | はい | モデルが応答に使用する音声。サポートされている音声には、alloy、ash、ballad、coral、echo、fable、nova、onyx、sage、および shimmer が含まれます。 |

#### `temperature`

- タイプ：数値または null
- 必須：いいえ
- デフォルト値：1

使用するサンプリング温度。0から2の間。高い値（例：0.8）は出力をよりランダムにし、低い値（例：0.2）は出力をより集中的で決定論的にします。通常、この値または `top_p` のいずれかを変更することをお勧めしますが、両方を同時に変更しないでください。

#### `top_p`

- タイプ：数値または null
- 必須：いいえ
- デフォルト値：1

核サンプリングと呼ばれる、サンプリング温度の代替方法。モデルは、top_pの確率質量を持つトークンの結果を考慮します。したがって、0.1は、上位10%の確率質量を含むトークンのみが考慮されることを意味します。

通常、この値または `temperature` のいずれかを変更することをお勧めしますが、両方を同時に変更しないでください。

#### `n`

- タイプ：整数または null
- 必須：いいえ
- デフォルト値：1

入力メッセージごとに生成するチャット補完の選択肢の数。生成されたすべての選択肢のトークン数に基づいて課金されることに注意してください。`n` を1に保つことでコストを最小限に抑えることができます。

#### `stop`

- タイプ：文字列/配列/null
- 必須：いいえ
- デフォルト値：null
- 最新の推論モデルおよび .o3、o4-mini ではサポートされていません

APIがそれ以上のトークンの生成を停止する最大4つのシーケンス。返されるテキストには停止シーケンスは含まれません。

#### `max_tokens`

- タイプ：整数または null
- 必須：いいえ

チャット補完で生成できる最大トークン数。この値は、APIを通じて生成されるテキストのコストを制御するために使用できます。

この値は現在非推奨であり、代わりに `max_completion_tokens` が使用され、`o1` シリーズモデルとは互換性がありません。

#### `max_completion_tokens`

- タイプ：整数または null
- 必須：いいえ

可視出力トークンと推論トークンを含む、補完で生成できるトークン数の上限。

#### `presence_penalty`

- タイプ：数値または null
- 必須：いいえ
- デフォルト値：0

-2.0から2.0までの数値。正の値は、新しいトークンがこれまでにテキストに現れた回数に基づいてペナルティを課し、モデルが新しいトピックについて議論する可能性を高めます。

#### `frequency_penalty`

- タイプ：数値または null
- 必須：いいえ
- デフォルト値：0

-2.0から2.0までの数値。正の値は、新しいトークンがこれまでにテキストに存在する頻度に基づいてペナルティを課し、モデルが同じ行を逐語的に繰り返す可能性を減らします。

#### `logit_bias`

- タイプ：map
- 必須：いいえ
- デフォルト値：null

指定されたトークンが補完に表示される可能性を変更します。

トークン（トークナイザーのトークンIDで指定）を、-100から100までの関連バイアス値にマッピングするJSONオブジェクトを受け入れます。数学的には、バイアスはサンプリング前にモデルが生成するロジットに追加されます。正確な効果はモデルによって異なりますが、-1から1の間の値は選択の可能性を減らすか増やすはずです。-100や100のような値は、関連するトークンが禁止されるか、排他的に選択されるようにするはずです。

#### `logprobs`

- タイプ：ブール値または null
- 必須：いいえ
- デフォルト値：false

出力トークンの対数確率を返すかどうか。trueの場合、`message.content` 内の各出力トークンの対数確率が返されます。

#### `user`

- タイプ：文字列
- 必須：いいえ

エンドユーザーを表す一意の識別子。OpenAIが乱用を監視および検出するのに役立ちます。[詳細はこちら](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids)。

#### `service_tier`

- タイプ：文字列または null
- 必須：いいえ
- デフォルト値：auto

リクエストの処理に使用されるレイテンシ層を指定します。このパラメータは、スケール層サービスを購読している顧客に関連します：

- 'auto' に設定され、プロジェクトでスケール層が有効になっている場合、システムはスケール層のクレジットを使い果たすまで使用します
- 'auto' に設定され、プロジェクトでスケール層が有効になっていない場合、リクエストはデフォルトのサービス層で処理され、稼働時間SLAが低く、レイテンシ保証はありません
- 'default' に設定されている場合、リクエストはデフォルトのサービス層で処理され、稼働時間SLAが低く、レイテンシ保証はありません
- 'flex' に設定されている場合、リクエストはFlex Processingサービス層で処理されます。詳細についてはドキュメントを参照してください。
- 設定されていない場合、デフォルトの動作は 'auto' です
- このパラメータが設定されている場合、レスポンスボディには使用された service_tier が含まれます

#### `stream_options`

- タイプ：オブジェクトまたは null
- 必須：いいえ
- デフォルト値：null

ストリーミング応答のオプション。`stream: true` が設定されている場合にのみ使用されます。

**可能な属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `include_usage` | ブール値 | いいえ | 設定されている場合、data: [DONE] メッセージの前に、追加のチャンクがストリーミングされます。このチャンクの usage フィールドには、リクエスト全体のトークン使用統計が表示され、choices フィールドは常に空の配列です。他のすべてのチャンクにも usage フィールドが含まれますが、値は null です。注：ストリームが中断された場合、リクエストの合計トークン使用量を含む最終的な使用チャンクを受け取らない可能性があります。 |

#### `response_format`

- タイプ：オブジェクト
- 必須：いいえ

モデルが出力しなければならない形式を指定します。

- `{ "type": "json_schema", "json_schema": {...} }` に設定すると、構造化出力が有効になり、モデルが提供された JSON スキーマに一致することが保証されます。
- `{ "type": "json_object" }` に設定すると、JSON モードが有効になり、モデルが生成するメッセージが有効な JSON であることが保証されます。

重要：JSON モードを使用する場合、システムまたはユーザーメッセージを通じて、モデルに JSON を生成するように指示する必要もあります。そうしないと、モデルがトークン制限に達するまで無限の空白を生成する可能性があります。

**可能なタイプ：**

| タイプ | 説明 |
|------|------|
| **text** | デフォルトの応答形式。テキスト応答の生成に使用されます。 |
| **json_schema** | JSON Schema 応答形式。構造化された JSON 応答の生成に使用されます。構造化出力の詳細についてはこちらをご覧ください。 |
| **json_object** | JSON オブジェクト応答形式。JSON 応答を生成するための古い方法です。サポートされているモデルでは、json_schema が推奨されます。 |

**text 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `type` | 文字列 | はい | 定義されている応答形式のタイプ。常に `text` です。 |

**json_schema 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `json_schema` | オブジェクト | はい | JSON Schema を含む構造化出力構成オプション。 |
| `type` | 文字列 | はい | 定義されている応答形式のタイプ。常に `json_schema` です。 |

**json_schema.json_schema 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `name` | 文字列 | はい | 応答形式の名前。a-z、A-Z、0-9、またはアンダースコアとハイフンを含む必要があり、最大長は64です。 |
| `description` | 文字列 | いいえ | 応答形式の目的の説明。モデルはこれを使用して、その形式で応答する方法を決定します。 |
| `schema` | オブジェクト | いいえ | JSON Schema オブジェクトとして記述された応答形式のスキーマ。 |
| `strict` | ブール値または null | いいえ | 出力生成時に厳密なスキーマ準拠を有効にするかどうか。trueに設定されている場合、モデルは常に schema フィールドで定義された正確なスキーマに従います。strict が true の場合、JSON Schema のサブセットのみがサポートされます。 |

**json_object 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `type` | 文字列 | はい | 定義されている応答形式のタイプ。常に `json_object` です。 |

#### `seed`

- タイプ：整数または null
- 必須：いいえ
ベータ機能。指定された場合、当社のシステムは決定論的なサンプリングを行うために最善を尽くし、同じシードとパラメータを持つ繰り返しのリクエストは同じ結果を返すはずです。決定論は保証されません。バックエンドの変更を監視するために、応答パラメータの system_fingerprint を参照する必要があります。

#### `tools`

- タイプ：配列
- 必須：いいえ

モデルが呼び出す可能性のあるツールのリスト。現在、関数のみがツールとしてサポートされています。このパラメータを使用して、モデルがJSON入力を生成する可能性のある関数のリストを提供します。最大128個の関数がサポートされています。

**属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `function` | オブジェクト | はい | 呼び出す関数の情報 |
| `type` | 文字列 | はい | ツールのタイプ。現在、function のみがサポートされています。 |

**function 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `name` | 文字列 | はい | 呼び出す関数の名前。a-z、A-Z、0-9、またはアンダースコアとハイフンを含む必要があり、最大長は64です。 |
| `description` | 文字列 | いいえ | 関数の機能の説明。モデルはこれを使用して、いつ、どのように関数を呼び出すかを決定します。 |
| `parameters` | オブジェクト | いいえ | 関数が受け入れる引数。JSON Schema オブジェクトとして記述されます。例についてはガイドを、フォーマットドキュメントについてはJSON Schemaリファレンスを参照してください。parameters を省略すると、空の引数リストを持つ関数が定義されます。 |
| `strict` | ブール値または null | いいえ | デフォルト値：false。関数呼び出しの生成時に厳密なスキーマ準拠を有効にするかどうか。trueに設定されている場合、モデルは parameters フィールドで定義された正確なスキーマに従います。strict が true の場合、JSON Schema のサブセットのみがサポートされます。詳細については、関数呼び出しガイドの構造化出力セクションを参照してください。 |

#### `functions`

- タイプ：配列
- 必須：いいえ
- 注意：非推奨。`tools` が推奨されます。

モデルがJSON入力を生成する可能性のある関数のリスト。

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `name` | 文字列 | はい | 呼び出す関数の名前。a-z、A-Z、0-9、またはアンダースコアとハイフンを含む必要があり、最大長は64です。 |
| `description` | 文字列 | いいえ | 関数の機能の説明。モデルはこれを使用して、いつ、どのように関数を呼び出すかを決定します。 |
| `parameters` | オブジェクト | いいえ | 関数が受け入れる引数。JSON Schema オブジェクトとして記述されます。parameters を省略すると、空の引数リストを持つ関数が定義されます。 |

#### `tool_choice`

- タイプ：文字列またはオブジェクト
- 必須：いいえ

モデルがどのツールを呼び出すか（もしあれば）を制御します：
- `none`：モデルはツールを呼び出さず、メッセージを生成します
- `auto`：モデルはメッセージの生成または1つ以上のツールの呼び出しを選択できます
- `required`：モデルは1つ以上のツールを呼び出す必要があります
- `{"type": "function", "function": {"name": "my_function"}}`：モデルに特定のツールを強制的に呼び出させます

ツールがない場合は `none` がデフォルト、ツールがある場合は `auto` がデフォルトです。

**可能なタイプ：**

| タイプ | 説明 |
|------|------|
| **文字列** | none は、モデルがツールを呼び出さず、メッセージを生成することを意味します。auto は、モデルがメッセージの生成または1つ以上のツールの呼び出しを選択できることを意味します。required は、モデルが1つ以上のツールを呼び出す必要があることを意味します。 |
| **オブジェクト** | モデルが使用すべきツールを指定します。モデルに特定の関数を強制的に呼び出させるために使用されます。 |

**オブジェクト属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `function` | オブジェクト | はい | 関数情報を含むオブジェクト |
| `type` | 文字列 | はい | ツールのタイプ。現在、function のみがサポートされています。 |

**function 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `name` | 文字列 | はい | 呼び出す関数の名前。 |

#### `function_call`

- タイプ：文字列またはオブジェクト
- 必須：いいえ
- デフォルト値：関数がない場合は `none`、関数がある場合は `auto`
- 注意：非推奨。`tool_choice` が推奨されます。

モデルがどの関数を呼び出すか（もしあれば）を制御します：

- `none`：モデルは関数を呼び出さず、メッセージを生成します
- `auto`：モデルはメッセージの生成または関数の呼び出しを選択できます
- `{"name": "my_function"}`：モデルに特定の関数を強制的に呼び出させます

**オブジェクトタイプ属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `name` | 文字列 | はい | 呼び出す関数の名前。 |

#### `parallel_tool_calls`

- タイプ：ブール値
- 必須：いいえ
- デフォルト値：true

ツール使用中に並列関数呼び出しを有効にするかどうか。

#### `stream`

- タイプ：ブール値または null
- 必須：いいえ
- デフォルト値：false

trueに設定されている場合、モデル応答データは、生成時にサーバー送信イベントストリームを通じてクライアントにストリーミングされます。詳細については、以下のストリーミング応答セクション、およびストリーミングイベントの処理方法についてはストリーミング応答ガイドを参照してください。

#### `top_logprobs`

- タイプ：整数または null
- 必須：いいえ

0から20までの整数。各トークン位置で返される最も可能性の高いトークンの数を指定し、それぞれに関連付けられた対数確率があります。このパラメータを使用する場合、`logprobs` をtrueに設定する必要があります。

#### `web_search_options`

- タイプ：オブジェクト
- 必須：いいえ

このツールは、応答に関連する結果を得るためにウェブを検索します。ウェブ検索ツールの詳細については、こちらを参照してください。

**可能な属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `search_context_size` | 文字列 | いいえ | デフォルト値：medium。検索に使用するコンテキストウィンドウのスペース量の高レベルなガイダンス。オプションの値は low、medium、または high です。medium がデフォルト値です。 |
| `user_location` | オブジェクトまたは null | いいえ | 検索の近似位置パラメータ。 |

**user_location 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `approximate` | オブジェクト | はい | 検索の近似位置パラメータ。 |

**approximate 属性：**

| 属性 | タイプ | 必須 | 説明 |
|------|------|------|------|
| `city` | 文字列 | いいえ | ユーザーの都市の自由テキスト入力。例：San Francisco。 |
| `country` | 文字列 | いいえ | ユーザーの2文字のISO国コード。例：US。 |
| `region` | 文字列 | いいえ | ユーザーの地域の自由テキスト入力。例：California。 |
| `timezone` | 文字列 | いいえ | ユーザーのIANAタイムゾーン。例：America/Los_Angeles。 |
| `type` | 文字列 | はい | 位置近似タイプ。常に approximate です。 |

## 📥 レスポンス

### チャット補完オブジェクト

チャット補完オブジェクトを返します。リクエストがストリーミングされた場合は、チャット補完チャンクオブジェクトのストリーミングシーケンスを返します。

#### `id` 
- タイプ：文字列
- 説明：応答の一意の識別子

#### `object`
- タイプ：文字列
- 説明：オブジェクトタイプ。値は "chat.completion"

#### `created`
- タイプ：整数
- 説明：応答作成のタイムスタンプ

#### `model`
- タイプ：文字列
- 説明：使用されたモデルの名前

#### `system_fingerprint`
- タイプ：文字列
- 説明：モデルが実行されたバックエンド構成を示すシステム指紋識別子。シードリクエストパラメータと組み合わせて使用​​し、決定論に影響を与える可能性のあるバックエンドの変更がいつ行われたかを監視できます。

#### `choices`
- タイプ：配列
- 説明：生成された応答オプションのリストが含まれます。n が 1 より大きい場合、複数のオプションが存在する可能性があります。
- 属性:
  - `index`: オプションがオプションリスト内のインデックス。
  - `message`: モデルによって生成されたチャット補完メッセージ。
    - `role`: メッセージ作成者のロール。
    - `content`: メッセージの内容。null の可能性があります。
    - `refusal`: モデルによって生成された拒否メッセージ。null の可能性があります。
    - `annotations`: 該当する場合に提供されるメッセージの注釈。例：ウェブ検索ツールが使用された場合。
      - `type`: 注釈タイプ。URL参照の場合は常に "url_citation"。
      - `url_citation`: ウェブ検索が使用された場合のURL参照。
        - `start_index`: メッセージ内のURL参照の最初の文字のインデックス。
        - `end_index`: メッセージ内のURL参照の最後の文字のインデックス。
        - `url`: ウェブリソースのURL。
        - `title`: ウェブリソースのタイトル。
    - `audio`: 音声出力モダリティがリクエストされた場合、このオブジェクトにはモデルからの音声応答のデータが含まれます。
      - `data`: モデルによって生成されたBase64エンコードされた音声バイト。フォーマットはリクエストで指定されます。
      - `id`: この音声応答の一意の識別子。
      - `transcript`: モデルによって生成された音声の文字起こし。
      - `expires_at`: この音声応答がサーバー上でマルチターン対話に使用できるUnixタイムスタンプ（秒）。
    - `function_call`: （非推奨）モデルによって生成された、呼び出すべき関数の名前と引数。`tool_calls` に置き換えられました。
      - `name`: 呼び出す関数の名前。
      - `arguments`: 関数を呼び出すためにモデルによってJSON形式で生成された引数。モデルは必ずしも有効なJSONを生成するとは限らず、関数のスキーマで定義されていない引数を生成する可能性があることに注意してください。関数を呼び出す前に、コードで引数を検証してください。
    - `tool_calls`: モデルによって生成された、関数呼び出しなどのツール呼び出し。
      - `id`: ツール呼び出しのID。
      - `type`: ツールのタイプ。現在、function のみがサポートされています。
      - `function`: モデルが呼び出す関数。
        - `name`: 呼び出す関数の名前。
        - `arguments`: 関数を呼び出すためにモデルによってJSON形式で生成された引数。モデルは必ずしも有効なJSONを生成するとは限らず、関数のスキーマで定義されていない引数を生成する可能性があることに注意してください。関数を呼び出す前に、コードで引数を検証してください。
  - `logprobs`: 対数確率情報。
    - `content`: 対数確率情報を持つメッセージコンテンツトークンのリスト。
      - `token`: トークン。
      - `logprob`: このトークンの対数確率。上位20個の最も可能性の高いトークン内にある場合。そうでない場合は、このトークンが非常に可能性が低いことを示すために -9999.0 の値が使用されます。
      - `bytes`: トークンを表すUTF-8バイト表現の整数のリスト。文字が複数のトークンで表され、正しいテキスト表現を生成するためにバイト表現を結合する必要がある場合に役立ちます。トークンにバイト表現がない場合は null の可能性があります。
      - `top_logprobs`: このトークン位置で最も可能性の高いトークンとその対数確率のリスト。まれに、返される top_logprobs の数がリクエストされた数よりも少ない場合があります。
    - `refusal`: 対数確率情報を持つメッセージ拒否トークンのリスト。
  - `finish_reason`: モデルがトークンの生成を停止した理由。モデルが自然な停止点または提供された停止シーケンスに到達した場合は "stop"、リクエストで指定された最大トークン数に達した場合は "length"、コンテンツフィルターのフラグが原因でコンテンツが省略された場合は "content_filter"、モデルがツールを呼び出した場合は "tool_calls"、モデルが関数を呼び出した場合は "function_call"（非推奨）。

#### `usage`
- タイプ：オブジェクト
- 説明：補完リクエストの使用統計情報。
- 属性:
  - `prompt_tokens`: プロンプト内のトークン数。
  - `completion_tokens`: 生成された補完内のトークン数。
  - `total_tokens`: リクエストで使用された合計トークン数（プロンプト + 補完）。
  - `prompt_tokens_details`: プロンプトで使用されたトークンの内訳。
    - `cached_tokens`: プロンプトに存在するキャッシュされたトークン。
    - `audio_tokens`: プロンプトに存在する音声入力トークン。
  - `completion_tokens_details`: 補完で使用されたトークンの内訳。
    - `reasoning_tokens`: モデルによって生成された推論トークン。
    - `audio_tokens`: モデルによって生成された音声トークン。
    - `accepted_prediction_tokens`: 予測出力を使用した場合、補完に現れた予測内のトークン数。
    - `rejected_prediction_tokens`: 予測出力を使用した場合、補完に現れなかった予測内のトークン数。ただし、推論トークンと同様に、これらのトークンは課金、出力、およびコンテキストウィンドウ制限の合計補完トークンにカウントされます。

#### `service_tier`
- タイプ：文字列または null
- 説明：リクエストの処理に使用されるレイテンシ層を指定します。このパラメータは、スケール層サービスを購読している顧客に関連します：
  - 'auto' に設定され、プロジェクトでスケール層が有効になっている場合、システムはスケール層のクレジットを使い果たすまで使用します
  - 'auto' に設定され、プロジェクトでスケール層が有効になっていない場合、リクエストはデフォルトのサービス層で処理され、稼働時間SLAが低く、レイテンシ保証はありません
  - 'default' に設定されている場合、リクエストはデフォルトのサービス層で処理され、稼働時間SLAが低く、レイテンシ保証はありません
  - 'flex' に設定されている場合、リクエストはFlex Processingサービス層で処理されます
  - 設定されていない場合、デフォルトの動作は 'auto' です
  - このパラメータが設定されている場合、レスポンスボディには使用された service_tier が含まれます

#### チャット補完オブジェクトレスポンス例

```json
{
  "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
  "object": "chat.completion",
  "created": 1741570283,
  "model": "gpt-4o-2024-08-06",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "图片展示了一条穿过茂密绿色草地或草甸的木制栈道。天空湛蓝，点缀着几朵散落的云彩，给整个场景营造出宁静祥和的氛围。背景中可以看到树木和灌木丛。",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1117,
    "completion_tokens": 46,
    "total_tokens": 1163,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default",
  "system_fingerprint": "fp_fc9f1d7035"
}
```

### チャット補完リストオブジェクト

複数のチャット補完が返される場合、APIはチャット補完リストオブジェクトを返すことがあります。

#### `object`
- タイプ：文字列
- 説明：オブジェクトタイプ。常に "list"

#### `data`
- タイプ：配列
- 説明：チャット補完オブジェクトの配列

#### `first_id`
- タイプ：文字列
- 説明：データ配列内の最初のチャット補完の識別子

#### `last_id`
- タイプ：文字列
- 説明：データ配列内の最後のチャット補完の識別子

#### `has_more`
- タイプ：ブール値
- 説明：さらにチャット補完が利用可能かどうかを示します

#### チャット補完リストレスポンス例

```json
{
  "object": "list",
  "data": [
    {
      "object": "chat.completion",
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
      "model": "gpt-4o-2024-08-06",
      "created": 1738960610,
      "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
      "tool_choice": null,
      "usage": {
        "total_tokens": 31,
        "completion_tokens": 18,
        "prompt_tokens": 13
      },
      "seed": 4944116822809979520,
      "top_p": 1.0,
      "temperature": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "system_fingerprint": "fp_50cad350e4",
      "input_user": null,
      "service_tier": "default",
      "tools": null,
      "metadata": {},
      "choices": [
        {
          "index": 0,
          "message": {
            "content": "电路之心低吟，\n在寂静中学习模式—\n未来的宁静火花。",
            "role": "assistant",
            "tool_calls": null,
            "function_call": null
          },
          "finish_reason": "stop",
          "logprobs": null
        }
      ],
      "response_format": null
    }
  ],
  "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
  "has_more": false
}
```

### チャット補完メッセージリストオブジェクト

チャット補完メッセージリストオブジェクトは、チャットメッセージのリストを表します。

#### `object`
- タイプ：文字列
- 説明：オブジェクトタイプ。常に "list"

#### `data`
- タイプ：配列
- 説明：チャット補完メッセージオブジェクトの配列。各メッセージオブジェクトには以下の属性が含まれます：
  - `id`: チャットメッセージの識別子
  - `role`: メッセージ作成者のロール
  - `content`: メッセージの内容。null の可能性があります
  - `name`: メッセージ送信者の名前。null の可能性があります
  - `refusal`: モデルによって生成された拒否メッセージ。null の可能性があります
  - `annotations`: 該当する場合に提供されるメッセージの注釈。例：ウェブ検索ツールが使用された場合
    - `type`: 注釈タイプ。URL参照の場合は常に "url_citation"
    - `url_citation`: ウェブ検索が使用された場合のURL参照
      - `start_index`: メッセージ内のURL参照の最初の文字のインデックス
      - `end_index`: メッセージ内のURL参照の最後の文字のインデックス
      - `url`: ウェブリソースのURL
      - `title`: ウェブリソースのタイトル
  - `audio`: 音声出力モダリティがリクエストされた場合、このオブジェクトにはモデルからの音声応答のデータが含まれます
    - `data`: モデルによって生成されたBase64エンコードされた音声バイト。フォーマットはリクエストで指定されます
    - `id`: この音声応答の一意の識別子
    - `transcript`: モデルによって生成された音声の文字起こし
    - `expires_at`: この音声応答がサーバー上でマルチターン対話に使用できるUnixタイムスタンプ（秒）
  - `function_call`: （非推奨）モデルによって生成された、呼び出すべき関数の名前と引数。`tool_calls` に置き換えられました
    - `name`: 呼び出す関数の名前
    - `arguments`: 関数を呼び出すためにモデルによってJSON形式で生成された引数
  - `tool_calls`: モデルによって生成された、関数呼び出しなどのツール呼び出し
    - `id`: ツール呼び出しのID
    - `type`: ツールのタイプ。現在、function のみがサポートされています
    - `function`: モデルが呼び出す関数
      - `name`: 呼び出す関数の名前
      - `arguments`: 関数を呼び出すためにモデルによってJSON形式で生成された引数

#### `first_id`
- タイプ：文字列
- 説明：データ配列内の最初のチャットメッセージの識別子

#### `last_id`
- タイプ：文字列
- 説明：データ配列内の最後のチャットメッセージの識別子

#### `has_more`
- タイプ：ブール値
- 説明：さらにチャットメッセージが利用可能かどうかを示します

#### チャット補完メッセージリストレスポンス例

```json
{
  "object": "list",
  "data": [
    {
      "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
      "role": "user",
      "content": "写一首关于人工智能的俳句",
      "name": null,
      "content_parts": null
    }
  ],
  "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
  "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
  "has_more": false
}
```